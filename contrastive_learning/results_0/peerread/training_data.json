{
    "metadata": {
        "config": {
            "epochs": 200,
            "batch_size": 512,
            "model": "LargeContrastiveEncoder(\n  (network): Sequential(\n    (0): Linear(in_features=2048, out_features=8192, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.0, inplace=False)\n    (3): Linear(in_features=8192, out_features=8192, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.0, inplace=False)\n    (6): Linear(in_features=8192, out_features=4096, bias=True)\n    (7): ReLU()\n    (8): Dropout(p=0.0, inplace=False)\n    (9): Linear(in_features=4096, out_features=4096, bias=True)\n    (10): ReLU()\n    (11): Dropout(p=0.0, inplace=False)\n    (12): Linear(in_features=4096, out_features=2048, bias=True)\n    (13): ReLU()\n    (14): Dropout(p=0.0, inplace=False)\n    (15): Linear(in_features=2048, out_features=2048, bias=True)\n    (16): ReLU()\n    (17): Dropout(p=0.0, inplace=False)\n    (18): Linear(in_features=2048, out_features=1024, bias=True)\n    (19): ReLU()\n    (20): Dropout(p=0.0, inplace=False)\n    (21): Linear(in_features=1024, out_features=512, bias=True)\n  )\n)",
            "criterion": "TripletMarginLoss()",
            "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 1e-05\n    maximize: False\n    weight_decay: 0\n)",
            "end_margin": 0.5,
            "steps_per_batch_train": 9
        },
        "dataset_sizes": {
            "total": 5616,
            "train": 4492,
            "validation": 1124
        }
    },
    "train_loss_history": [
        0.3000921308994293,
        0.22367213666439056,
        0.12698383629322052,
        0.09548961371183395,
        0.15962360799312592,
        0.04352162033319473,
        0.05634446069598198,
        0.03933010250329971,
        0.043276797980070114,
        0.02865777350962162,
        0.05575471371412277,
        0.06584378331899643,
        0.06141716614365578,
        0.024668533354997635,
        0.043600939214229584,
        0.021081939339637756,
        0.012541359290480614,
        0.01854104734957218
    ],
    "val_loss_history": [
        0.49997971455256146,
        0.49993454416592914,
        0.49978020787239075,
        0.4991813103357951,
        0.497173806031545,
        0.48926769693692523,
        0.46665451924006146,
        0.4310430387655894,
        0.3596368233362834,
        0.3200969596703847,
        0.296012004216512,
        0.32570276657740277,
        0.30974075198173523,
        0.2987304429213206,
        0.25696271161238354,
        0.2550229827562968,
        0.2812569936116536,
        0.23871042827765146,
        0.20657661060492197,
        0.24628232916196188,
        0.25420371691385907,
        0.21159822742144266,
        0.2001553773880005,
        0.19163958728313446,
        0.1713359554608663,
        0.17177751660346985,
        0.1591778745253881,
        0.12516025453805923,
        0.13114262372255325,
        0.13757000863552094,
        0.1418029467264811,
        0.13789458572864532,
        0.15643952041864395,
        0.1277663136521975,
        0.13543005039294562,
        0.1025693913300832,
        0.12249723573525746,
        0.11286566654841106,
        0.09324521819750468,
        0.09737765540679295,
        0.09634674837191899,
        0.09992125630378723,
        0.09548365076382954,
        0.10616583377122879,
        0.09032018482685089,
        0.10935954997936885,
        0.10452614724636078,
        0.08887797345717748,
        0.09538738677899043,
        0.07769932349522908,
        0.07503582164645195,
        0.0928300271431605,
        0.06396593401829402,
        0.10644017904996872,
        0.12021235376596451,
        0.17657378315925598,
        0.08030065149068832,
        0.08224316189686458,
        0.07082711532711983,
        0.07171259572108586,
        0.07682749877373378,
        0.05476147929827372,
        0.06412960464755695,
        0.07023847848176956,
        0.06175355613231659,
        0.0724885140856107,
        0.06787453343470891,
        0.07398041089375813,
        0.058194718013207115,
        0.05634727329015732,
        0.06469680368900299,
        0.050050895661115646,
        0.06340333943565686,
        0.05594360580046972,
        0.05023044596115748,
        0.06649322931965192,
        0.11394249399503072,
        0.06414010748267174,
        0.05119946474830309,
        0.08120691527922948,
        0.12210473418235779,
        0.05830898632605871,
        0.07791273295879364,
        0.04353972182919582,
        0.04885356252392133,
        0.06402688970168431,
        0.04721911003192266,
        0.04610896483063698,
        0.047017947460214295,
        0.04442077502608299,
        0.0499739870429039,
        0.04350991050402323,
        0.05011805767814318,
        0.09152635931968689,
        0.04561654105782509,
        0.04153461009263992,
        0.056784710536400475,
        0.0805584688981374,
        0.04643781234820684,
        0.05984288454055786,
        0.04810370380679766,
        0.04332522923747698,
        0.03767878438035647,
        0.038109335427482925,
        0.036731539915005364,
        0.0394935371975104,
        0.05684265245993932,
        0.041684101025263466,
        0.03381254027287165,
        0.049221668392419815,
        0.03662893051902453,
        0.044736733039220176,
        0.04129531731208166,
        0.041395995765924454,
        0.04778431604305903,
        0.04512941588958105,
        0.039276467015345894,
        0.03143709090848764,
        0.03604783738652865,
        0.035727171848217644,
        0.05095325907071432,
        0.032128519068161644,
        0.03328064425537983,
        0.051678268859783806,
        0.0463224413494269,
        0.040119328846534096,
        0.036058212320009865,
        0.20544488728046417,
        0.12767712523539862,
        0.0988515888651212,
        0.08553419510523479,
        0.05704456071058909,
        0.06120767196019491,
        0.06031595294674238,
        0.07151561106244723,
        0.0681137889623642,
        0.06602486222982407,
        0.052667575577894844,
        0.0582457867761453,
        0.06232880800962448,
        0.057847859958807625,
        0.04777410067617893,
        0.06002012516061465,
        0.04093098392089208,
        0.04118893419702848,
        0.06241408362984657,
        0.048178998132546745,
        0.046289799734950066,
        0.03670774462322394,
        0.04765748853484789,
        0.05396121243635813,
        0.03430910408496857,
        0.0433297244211038,
        0.036894857262571655,
        0.04222972815235456,
        0.04100640614827474,
        0.04077656132479509,
        0.049166664481163025,
        0.04744420945644379,
        0.04075159256656965,
        0.04786197220285734,
        0.0401251365741094,
        0.03332922731836637,
        0.025803165665517252,
        0.03285563737154007,
        0.04046777387460073,
        0.03034561996658643,
        0.035099839170773826,
        0.030191347002983093,
        0.033955844740072884,
        0.03188044764101505,
        0.02028439457838734,
        0.02794080724318822,
        0.04512778421243032,
        0.03363846739133199,
        0.02718565488855044,
        0.0267982945467035,
        0.022828612476587296,
        0.029093635268509388,
        0.028846516584356625,
        0.037789263452092804,
        0.03808519120017687,
        0.019679197420676548,
        0.028727297981580097,
        0.01909857988357544,
        0.03148734259108702,
        0.04513827214638392,
        0.028066990276177723,
        0.02276315540075302,
        0.046479428807894387,
        0.017020335265745718,
        0.022531685574601095,
        0.023014120136698086,
        0.02322385646402836,
        0.023572749458253384,
        0.026447154271105926,
        0.03876799903810024,
        0.030280197970569134,
        0.03323805332183838,
        0.031200991322596867
    ]
}